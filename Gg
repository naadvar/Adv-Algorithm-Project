import pandas as pd
import numpy as np

# Simplified function to compute metrics and return a DataFrame in the desired format
def compute_metrics_simple(df, column, bestie_version, batch_ts, default_values=None):
    """
    Computes simplified metrics for the specified column in a pandas DataFrame.
    
    :param df: pandas DataFrame to compute metrics on.
    :param column: The column name to compute metrics for.
    :param bestie_version: The version of the data for metadata.
    :param batch_ts: The timestamp for the batch for metadata.
    :param default_values: List of default values to check for, e.g., ['997', '998', '999'].
    :return: pandas DataFrame with metrics for the specified column.
    """
    
    if default_values is None:
        default_values = ['997', '998', '999', '999997', '999998', '999999']
    
    total_rows = len(df)
    col_data = df[column]

    # Metrics to calculate
    metrics = [
        ("null_rate", col_data.isnull().mean()),
        ("zero_rate", (col_data == 0).mean())
    ]
    
    # Calculate default value rates
    metrics.extend([
        (f"default_value_{val}_rate", (col_data == val).mean()) for val in default_values
    ])
    
    # Exclude default values for core statistics
    valid_data = col_data[~col_data.isin(default_values)]
    core_stats = [
        ("avg", valid_data.mean()),
        ("stddev", valid_data.std()),
        ("min", valid_data.min()),
        ("max", valid_data.max()),
        ("count", valid_data.count())
    ]
    metrics.extend(core_stats)

    # Create the DataFrame
    result_df = pd.DataFrame({
        "bestie_version": bestie_version,
        "ol_batch_ts": batch_ts,
        "metric": [m[0] for m in metrics],
        column: [m[1] for m in metrics]
    })
    
    return result_df


# Example usage with the same DataFrame
data = {
    'BESTIE_VERSION': [10702]*22,
    'OL_BATCH_TS': ['2022-08-17 09:00:00']*10 + ['2022-08-17 10:00:00']*12,
    'EFX_AL_MPATP_1': [0, 100, 500, None, 997, 998, 999, 999997, 999998, -1, 
                       0, 100, 500, None, 997, 998, 999, 999997, 999998, 999999, -1],
    'FOO': [0]*22
}

df = pd.DataFrame(data)

# Compute metrics for 'EFX_AL_MPATP_1'
result_df = compute_metrics_simple(df, 'EFX_AL_MPATP_1', 10702, '2022-08-17 09:00:00')

# Display the result
import ace_tools as tools; tools.display_dataframe_to_user(name="Simplified Metrics Results", dataframe=result_df)



import numpy as np
import pandas as pd

def compute_metrics_simple(df, column, bestie_version, batch_ts, min_val, max_val, default_values=None):
    if default_values is None:
        default_values = [997, 998, 999, 999997, 999998, 999999, 999996]

    # Create a copy of the DataFrame and handle default values
    df2 = df.copy()
    df2[column] = df2[column].replace(default_values, np.nan)
    df2[column] = pd.to_numeric(df2[column], errors='coerce')

    # Calculate null and zero rates
    metrics = [
        ("null_rate", df2[column].isnull().mean()),
        ("zero_rate", (df2[column] == 0).mean())
    ]

    # Fill NaN with a valid number for further calculations
    col_data = df2[column].fillna(996).astype(int)

    # Extend metrics with default value rates
    metrics.extend([
        (f"default_value_{val}_rate", (col_data == val).mean()) for val in default_values
    ])
    
    # Valid data filtering (removing default values)
    valid_data = col_data[~col_data.isin(default_values)]

    # Core statistics
    core_stats = {
        "min": valid_data.min(),
        "max": valid_data.max(),
        "mean": valid_data.mean(),
        "count": len(valid_data)
    }

    # Extend metrics with core statistics
    metrics.extend(core_stats.items())

    # Return a DataFrame with all the metrics
    return pd.DataFrame(metrics, columns=["metric", "value"])

import numpy as np
import pandas as pd

def compute_metrics_simple(df, column, bestie_version, batch_ts, min_val, max_val, default_values=None):
    if default_values is None:
        default_values = [997, 998, 999, 999997, 999998, 999999, 999996]

    df2 = df.copy()

    # Replace the default values with NaN
    df2[column] = df2[column].replace(default_values, np.nan)

    # Convert column to numeric, coercing any errors to NaN
    df2[column] = pd.to_numeric(df2[column], errors='coerce')

    # Metrics calculation
    metrics = []

    # Null rate
    metrics.append(("null_rate", df2[column].isnull().mean()))

    # Zero rate
    metrics.append(("zero_rate", (df2[column] == 0).mean()))

    # Fill NaN values with 996 to avoid issues in further numeric computations
    col_data_filled = df2[column].fillna(996).astype(int)

    # Calculate default value rates
    for val in default_values:
        metrics.append((f"default_value_{val}_rate", (col_data_filled == val).mean()))

    # Replace 'None' strings with NaN, and fill remaining NaNs with 996
    df2[column] = df2[column].replace("None", np.nan)
    df2[column] = df2[column].fillna(996).astype(int)

    # Calculate statistics for non-default values
    valid_data = df2[column][~df2[column].isin(default_values)]

    # Core statistics
    core_stats = {
        "min": valid_data.min(),
        "max": valid_data.max(),
        "mean": valid_data.mean(),
        "count": len(valid_data)
    }

    for stat, value in core_stats.items():
        metrics.append((stat, value))

    # Convert metrics into a DataFrame for easy readability
    return pd.DataFrame(metrics, columns=["metric", "value"])
