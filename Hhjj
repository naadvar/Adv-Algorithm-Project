from pyspark.sql import SparkSession
from pyspark.sql.functions import col, udf
from pyspark.sql.types import StructType, StructField, StringType
import json

# Initialize Spark session
spark = SparkSession.builder.appName("ProcessJSON").getOrCreate()

# Load JSON file into DataFrame
df = spark.read.json("path/to/your/json_file.json")

# Function to check if a value is considered "zero" or "empty"
def is_zero_value(value):
    return value in [0, "0", None, "", "None"]

# Recursive function to remove zero values and track removed keys
def remove_zero_values(data, removed_keys, parent_key=""):
    if isinstance(data, dict):
        cleaned_data = {}
        for k, v in data.items():
            full_key = f"{parent_key}.{k}" if parent_key else k
            # Log the path and value encountered for debugging
            print(f"Checking key: {full_key} | Value: {v}")
            if is_zero_value(v):
                removed_keys.append(full_key)
            else:
                cleaned_data[k] = remove_zero_values(v, removed_keys, full_key)
        return cleaned_data
    elif isinstance(data, list):
        return [remove_zero_values(item, removed_keys, parent_key) for item in data]
    else:
        # Log each terminal value for debugging
        if is_zero_value(data):
            removed_keys.append(parent_key)
            return None
        return data

# UDF to process JSON and capture removed keys
def process_json(row):
    removed_keys = []
    cleaned_data = remove_zero_values(row, removed_keys)
    return json.dumps(cleaned_data), json.dumps(removed_keys)

# Register the UDF
process_json_udf = udf(process_json, StructType([
    StructField("cleaned_data", StringType()),
    StructField("removed_keys", StringType())
]))

# Apply the UDF to the specific JSON column in your DataFrame
result_df = df.withColumn("result", process_json_udf(col("experianResponse.experianCreditBureau")))

# Extract cleaned data and removed keys for analysis
final_df = result_df.select(
    col("result.cleaned_data").alias("cleaned_data"),
    col("result.removed_keys").alias("removed_keys")
)

# Show results
final_df.show(truncate=False)
